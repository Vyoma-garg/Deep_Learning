{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Finetuning_VGG16.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOlYjTG4vubodxVyWp0q3X+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vyoma-garg/Deep_Learning/blob/main/Finetuning_VGG16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PawkenIL-laD"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn  #all the NN network, CNN, Modules, loss functions, activation fns\n",
        "import torch.optim as optim  #SGD, ADAM\n",
        "import torch.nn.functional as F  #activation fn, \n",
        "from torch.utils.data import DataLoader  #easier data managemnet, creates mini batches of the data\n",
        "import torchvision.datasets as datasets   #standard datasets MNISt ,etc\n",
        "import torchvision.transforms as transforms  # transformations \n",
        "import torchvision"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqfHDi2FoP58"
      },
      "source": [
        "Setting device"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pm5Lamd6nVNm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "841d983c-2119-4081-845a-4881753fe8d6"
      },
      "source": [
        "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfxgXlJGoNHv"
      },
      "source": [
        "Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XahNlbbwnCor"
      },
      "source": [
        "in_channels=3\n",
        "num_classes=10\n",
        "learning_rate=0.001\n",
        "batch_size=1024\n",
        "num_epochs=5"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQRdYjItwXxA"
      },
      "source": [
        "Creating Identity class to do nothing where needed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCNeN_033SLl"
      },
      "source": [
        "class Identity(nn.Module): #inherit from nn.Module class\n",
        "    def __init__(self):  \n",
        "        super(Identity,self).__init__()   \n",
        "\n",
        "    def forward(self, x):    \n",
        "        return x\n"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5aayYZ1eL3t"
      },
      "source": [
        "# **Loading the pretrained model (pretrained=True)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2IY4M-aeK_F",
        "outputId": "ad70b6c8-9e69-41e3-c0a8-7fc0be93792b"
      },
      "source": [
        "model=torchvision.models.vgg16(pretrained=True)\n",
        "print(model)\n",
        "\n",
        "# If you want to do finetuning --> TRANSFER LEARNING then set requires_grad = False\n",
        "# Remove these two lines if you want to train entire model, and only want to load the pretrain weights.\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False #DOES NOT CHANGE THE WEIGHTS "
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): ReLU(inplace=True)\n",
            "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (20): ReLU(inplace=True)\n",
            "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): ReLU(inplace=True)\n",
            "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (27): ReLU(inplace=True)\n",
            "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSVwOvuwgdfJ"
      },
      "source": [
        "Modifying the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBJN4humgfR2",
        "outputId": "98829ceb-2d30-4ce8-8a36-f823d017493e"
      },
      "source": [
        "#model.avgpool= Identity()\n",
        "#model.classifier= nn.Linear(512,10)\n",
        "#model.to(device)\n",
        "#print(model)\n",
        "\n",
        "#same \n",
        "#model.avgpool=Identity()\n",
        "#model.classifier[0]= nn.Linear(512,10)\n",
        "#for i in range(1,7):\n",
        "# model.classifier[i]= Identity\n",
        "\n",
        "#diff\n",
        "model.avgpool=Identity()\n",
        "model.classifier= nn.Sequential(nn.Linear(512,100),\n",
        "                                nn.ReLU(),\n",
        "                               nn.Linear(100,10))\n",
        "model.to(device)\n",
        "print(model)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): ReLU(inplace=True)\n",
            "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (20): ReLU(inplace=True)\n",
            "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): ReLU(inplace=True)\n",
            "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (27): ReLU(inplace=True)\n",
            "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): Identity()\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=100, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=100, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8mvvCsMoGyO"
      },
      "source": [
        "Loading dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FA1BewQJnwrN",
        "outputId": "ada7e922-c68c-419b-f166-ffe082cede2b"
      },
      "source": [
        "train_dataset = datasets.CIFAR10(root = '/content', train = True , transform = transforms.ToTensor(), download = True)\n",
        "train_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True)\n",
        "test_dataset = datasets.CIFAR10(root = '/content', train = False , transform = transforms.ToTensor(), download = True)\n",
        "test_loader = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle = True)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dknhMuqKolO2"
      },
      "source": [
        "Loss and Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyqlZM30oksL"
      },
      "source": [
        "criterion= nn.CrossEntropyLoss()\n",
        "optimizer=optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jkbybF0pFz-"
      },
      "source": [
        "Train Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5147I3lpFTq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db2ff053-2a68-458c-afe2-051b40d85874"
      },
      "source": [
        "for epoch in range(num_epochs):\n",
        "  losses = []\n",
        "\n",
        "  for batch_idx,(data,targets) in enumerate(train_loader):  #enumerate helps in getting the batch index of the data\n",
        "     \n",
        "     #Get data to cuda\n",
        "      data = data.to(device)\n",
        "      targets = targets.to(device)\n",
        "\n",
        "      #print(data.shape)  #([64,1,28,28])  num of examples, number of channels(black white img), height width of each image\n",
        "                        \n",
        "      #get correct shape\n",
        "      #data=data.reshape(data.shape[0],-1)  #flatten to single dim: ([64,784])\n",
        "      #print(data.shape) \n",
        "\n",
        "      #forward\n",
        "      scores=model(data)\n",
        "      loss=criterion(scores, targets)\n",
        "      losses.append(loss.item())\n",
        "\n",
        "      #backward\n",
        "      optimizer.zero_grad() #\n",
        "      loss.backward()\n",
        "\n",
        "      #gradient descent or adam step\n",
        "      optimizer.step() #update weights based on the gradients\n",
        "  print(f\"Loss at epoch {epoch} is { sum(losses)/len(losses) :.5f}\")  \n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss at epoch 0 is 1.59687\n",
            "Loss at epoch 1 is 1.21371\n",
            "Loss at epoch 2 is 1.14643\n",
            "Loss at epoch 3 is 1.11209\n",
            "Loss at epoch 4 is 1.09173\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e38wBZ8ltU-H"
      },
      "source": [
        "Check accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJRYLHGZtWgb",
        "outputId": "87a83805-4dfa-44f6-e034-9075a1613f67"
      },
      "source": [
        "def check_accuracy(loader,model):\n",
        "  if loader.dataset.train:\n",
        "        print('Checking Accuracy on Training Data')\n",
        "  else:\n",
        "        print('Checking Accuracy on Test Data')\n",
        "  num_correct=0\n",
        "  num_samples=0\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():  #while checking accuracy no need to calculate the gradients again\n",
        "    for x,y in loader:\n",
        "      x=x.to(device=device)\n",
        "      y=y.to(device=device)\n",
        "      #x=x.reshape(x.shape[0],-1)\n",
        "\n",
        "      scores=model(x)  #64x10 shape of the scores, which is max of those 10 digits\n",
        "      values,predictions =scores.max(1)  #interested in index of the max value\n",
        "      num_correct += (predictions==y).sum()\n",
        "      num_samples += predictions.size(0)  #first dimension that is 64 x 10==64\n",
        "    print(f'Got {num_correct}/ {num_samples} with accuracy {float(num_correct)/float(num_samples)*100:.2f} \\n')\n",
        "\n",
        "  model.train()\n",
        "  \n",
        "\n",
        "check_accuracy(train_loader, model)\n",
        "check_accuracy(test_loader, model)\n",
        "\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checking Accuracy on Training Data\n",
            "Got 31373/ 50000 with accuracy 62.75 \n",
            "\n",
            "Checking Accuracy on Test Data\n",
            "Got 6119/ 10000 with accuracy 61.19 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dx5rNhLDkVQ-"
      },
      "source": [
        "# **WHEN PRETRAINED IS FALSE**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFhPcWJTkumB",
        "outputId": "b51301d3-004e-4cb3-9c14-91773e099dd8"
      },
      "source": [
        "model=torchvision.models.vgg16(pretrained=False)\n",
        "print(model)\n",
        "\n",
        "# If you want to do finetuning --> TRANSFER LEARNING then set requires_grad = False\n",
        "# Remove these two lines if you want to train entire model, and only want to load the pretrain weights.\n",
        "\n",
        "#for param in model.parameters():\n",
        "#    param.requires_grad = False #DOES NOT CHANGE THE WEIGHTS "
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): ReLU(inplace=True)\n",
            "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (20): ReLU(inplace=True)\n",
            "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): ReLU(inplace=True)\n",
            "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (27): ReLU(inplace=True)\n",
            "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Dropout(p=0.5, inplace=False)\n",
            "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): Dropout(p=0.5, inplace=False)\n",
            "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngDqTolDkumF"
      },
      "source": [
        "Modifying the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37vHnhX3kumH",
        "outputId": "6557a49f-f679-4bc3-a2e3-5d0a17b69b0d"
      },
      "source": [
        "#model.avgpool= Identity()\n",
        "#model.classifier= nn.Linear(512,10)\n",
        "#model.to(device)\n",
        "#print(model)\n",
        "\n",
        "#same \n",
        "#model.avgpool=Identity()\n",
        "#model.classifier[0]= nn.Linear(512,10)\n",
        "#for i in range(1,7):\n",
        "# model.classifier[i]= Identity\n",
        "\n",
        "#diff\n",
        "model.avgpool=Identity()\n",
        "model.classifier= nn.Sequential(nn.Linear(512,100),\n",
        "                                nn.ReLU(),\n",
        "                               nn.Linear(100,10))\n",
        "model.to(device)\n",
        "print(model)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "VGG(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): ReLU(inplace=True)\n",
            "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (20): ReLU(inplace=True)\n",
            "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): ReLU(inplace=True)\n",
            "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (27): ReLU(inplace=True)\n",
            "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): Identity()\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=512, out_features=100, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=100, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lmDbW-RkumJ"
      },
      "source": [
        "Train Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l00onDAMkumK",
        "outputId": "0cbf7211-6e5f-4927-8214-af19eba91123"
      },
      "source": [
        "for epoch in range(num_epochs):\n",
        "  losses = []\n",
        "\n",
        "  for batch_idx,(data,targets) in enumerate(train_loader):  #enumerate helps in getting the batch index of the data\n",
        "     \n",
        "     #Get data to cuda\n",
        "      data = data.to(device)\n",
        "      targets = targets.to(device)\n",
        "\n",
        "      #print(data.shape)  #([64,1,28,28])  num of examples, number of channels(black white img), height width of each image\n",
        "                        \n",
        "      #get correct shape\n",
        "      #data=data.reshape(data.shape[0],-1)  #flatten to single dim: ([64,784])\n",
        "      #print(data.shape) \n",
        "\n",
        "      #forward\n",
        "      scores=model(data)\n",
        "      loss=criterion(scores, targets)\n",
        "      losses.append(loss.item())\n",
        "\n",
        "      #backward\n",
        "      optimizer.zero_grad() #\n",
        "      loss.backward()\n",
        "\n",
        "      #gradient descent or adam step\n",
        "      optimizer.step() #update weights based on the gradients\n",
        "  print(f\"Loss at epoch {epoch} is { sum(losses)/len(losses) :.5f}\")  \n"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss at epoch 0 is 2.30402\n",
            "Loss at epoch 1 is 2.30402\n",
            "Loss at epoch 2 is 2.30403\n",
            "Loss at epoch 3 is 2.30402\n",
            "Loss at epoch 4 is 2.30403\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtGq_9TTkumL"
      },
      "source": [
        "Check accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7Kg2AYXkumM",
        "outputId": "fddeed63-ff34-42ba-b0f5-889e087164de"
      },
      "source": [
        "def check_accuracy(loader,model):\n",
        "  if loader.dataset.train:\n",
        "        print('Checking Accuracy on Training Data')\n",
        "  else:\n",
        "        print('Checking Accuracy on Test Data')\n",
        "  num_correct=0\n",
        "  num_samples=0\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():  #while checking accuracy no need to calculate the gradients again\n",
        "    for x,y in loader:\n",
        "      x=x.to(device=device)\n",
        "      y=y.to(device=device)\n",
        "      #x=x.reshape(x.shape[0],-1)\n",
        "\n",
        "      scores=model(x)  #64x10 shape of the scores, which is max of those 10 digits\n",
        "      values,predictions =scores.max(1)  #interested in index of the max value\n",
        "      num_correct += (predictions==y).sum()\n",
        "      num_samples += predictions.size(0)  #first dimension that is 64 x 10==64\n",
        "    print(f'Got {num_correct}/ {num_samples} with accuracy {float(num_correct)/float(num_samples)*100:.2f} \\n')\n",
        "\n",
        "  model.train()\n",
        "  \n",
        "\n",
        "check_accuracy(train_loader, model)\n",
        "check_accuracy(test_loader, model)\n",
        "\n"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checking Accuracy on Training Data\n",
            "Got 5000/ 50000 with accuracy 10.00 \n",
            "\n",
            "Checking Accuracy on Test Data\n",
            "Got 1000/ 10000 with accuracy 10.00 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}